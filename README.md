# Awesome_Modern_Hopfield_Networks
Paper list for Modern Hopfield Networks 


## Useful Materials 

* [**scholarpedia.org/article/Hopfield_network**](http://scholarpedia.org/article/Hopfield_network)

* [**Discrete Hopfield Network, September 20, 2015**](http://neupy.com/2015/09/20/discrete_hopfield_network.html) 





## Year 2024 


* **Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline**,
  Xiao Wang, Ju Huang, Shiao Wang, Chuanming Tang, Bo Jiang, Yonghong Tian, Jin Tang, Bin Luo,
  arXiv:2403.05839
  [[Paper](https://arxiv.org/pdf/2403.05839.pdf)]
  [[Code](https://github.com/Event-AHU/FELT_SOT_Benchmark)]
  [[DemoVideo](https://youtu.be/6zxiBHTqOhE?si=6ARRGFdBLSxyp3G8)]

* **Nonparametric Modern Hopfield Models**,
  Jerry Yao-Chieh Hu, Bo-Yu Chen, Dennis Wu, Feng Ruan, Han Liu
  [[Paper](https://arxiv.org/abs/2404.03900)]
  [[Code](https://github.com/MAGICS-LAB/NonparametricHopfield)] 

* **BiSHop: Bi-Directional Cellular Learning for Tabular Data with Generalized Sparse Modern Hopfield Model**,
  Chenwei Xu, Yu-Chao Huang, Jerry Yao-Chieh Hu, Weijian Li, Ammar Gilani, Hsi-Sheng Goan, Han Liu
  [[Paper](https://arxiv.org/abs/2404.03830)]
  [[Code](https://github.com/MAGICS-LAB/BiSHop)] 

* "**Reconstructing creative thoughts: Hopfield neural networks.**" Checiu, Denisa, Mathias Bode, and Radwa Khalil.  Neurocomputing (2024): 127324.
  [[Paper](https://www.sciencedirect.com/science/article/pii/S092523122400095X)]

* **On Computational Limits of Modern Hopfield Models: A Fine-Grained Complexity Analysis**, Jerry Yao-Chieh Hu, Thomas Lin, Zhao Song, Han Liu
  [[Paper](https://arxiv.org/abs/2402.04520)]

* **"Sequential memory with temporal predictive coding."** Tang, Mufeng, Helen Barron, and Rafal Bogacz. Advances in Neural Information Processing Systems 36 (2024).
  [[Paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/8a8b9c7f979e8819a7986b3ef825c08a-Abstract-Conference.html)]

* **Dense Hopfield Networks in the Teacher-Student Setting**, Robin Thériault, Daniele Tantari
  [[Paper](https://arxiv.org/abs/2401.04191)]




## Year 2023 


* **Outlier-Efficient Hopfield Layers for Large Transformer-Based Models**,
  Jerry Yao-Chieh Hu, Pei-Hsuan Chang, Robin Luo, Hong-Yu Chen, Weijian Li, Wei-Po Wang, Han Liu
  [[Paper](https://arxiv.org/abs/2404.03828)]

* **Uniform Memory Retrieval with Larger Capacity for Modern Hopfield Models**,
  Dennis Wu, Jerry Yao-Chieh Hu, Teng-Yun Hsiao, Han Liu
  [[Paper](https://arxiv.org/abs/2404.03827)] 

* **STanHop: Sparse Tandem Hopfield Model for Memory-Enhanced Time Series Prediction**,
  Dennis Wu, Jerry Yao-Chieh Hu, Weijian Li, Bo-Yu Chen, Han Liu
  [[Paper](https://arxiv.org/abs/2312.17346)] 

* **Neuron-Astrocyte Associative Memory**, arXiv:2311.08135, 
  Leo Kozachkov, Jean-Jacques Slotine, Dmitry Krotov
  [[Paper](https://arxiv.org/abs/2311.08135)] 

* Seidl, Philipp, et al. "**Improving few-and zero-shot reaction template prediction using modern hopfield networks.**" Journal of chemical information and modeling 62.9 (2022): 2111-2120.
  [[Paper](https://pubs.acs.org/doi/full/10.1021/acs.jcim.1c01065)]
  [[Code](https://github.com/ml-jku/mhn-react)]
  [[Video Tutorial](https://www.youtube.com/watch?v=xv3blKfpPww&ab_channel=ValenceLabs)]
  
* [NIPS-2023] **On Sparse Modern Hopfield Model**, Jerry Yao-Chieh Hu,
[[Paper](https://arxiv.org/abs/2309.12673)] 

* Jeremy Lu, Jonah Wu, **Understanding Hopfield Neural Networks**, [[Paper](https://jeremylu43.github.io/images/AMATH383%20-Final%20Paper.pdf)]

* Farah Aymen Mounir, **Surveying Hopfeild Neural Network and its Applications**, [[Paper](https://www.researchgate.net/profile/Farah-Aymen-3/publication/373844541_Surveying_Hopfeild_Neural_Network_and_its_Applications/links/650055b125ee6b7564e6a553/Surveying-Hopfeild-Neural-Network-and-its-Applications.pdf)] 

* Malyaban Bal , Abhronil Sengupta, **Sequence Learning Using Equilibrium Propagation**,
[[Paper](https://arxiv.org/pdf/2209.09626.pdf)] [[Code](https://github.com/NeuroCompLab-psu/EqProp-SeqLearning)] 

* Benjamin Hoover, et al, **Energy Transformer**,
[[Paper](https://arxiv.org/pdf/2302.07253.pdf)]
[[Code](https://github.com/bhoov/energy-transformer-jax)]

* Hamza Tahir Chaudhry, **Long Sequence Hopfield Memory** 
[[Paper](https://arxiv.org/abs/2306.04532)] 
  
* Ota, Toshihiro, and Masato Taki. "**iMixer: hierarchical Hopfield network implies an invertible, implicit and iterative MLP-Mixer.**" arXiv preprint arXiv:2304.13061 (2023).
[[Paper](https://arxiv.org/pdf/2304.13061.pdf)] 

* Auer, Andreas, et al. "**Conformal prediction for time series with Modern Hopfield Networks.**" arXiv preprint arXiv:2303.12783 (2023).
[[Paper](https://arxiv.org/pdf/2303.12783.pdf)]

* Ota, Toshihiro, et al. "**Learning with Partial Forgetting in Modern Hopfield Networks.**" International Conference on Artificial Intelligence and Statistics. PMLR, 2023.
[[Paper](https://proceedings.mlr.press/v206/ota23a/ota23a.pdf)]

* Chang S, Kopp M, Ghamisi P. **Dsfer-Net: A Deep Supervision and Feature Retrieval Network for Bitemporal Change Detection Using Modern Hopfield Networks**[J]. arXiv preprint arXiv:2304.01101, 2023.
[[Paper](https://arxiv.org/abs/2304.01101)] [[Code](https://github.com/ShizhenChang/Dsfer-Net)]

* Krotov, Dmitry. "**A new frontier for Hopfield networks.**" Nature Reviews Physics (2023): 1-2.
[[Paper](https://www.nature.com/articles/s42254-023-00595-y)]

* Burns, Thomas F., and Tomoki Fukai. "**Simplicial Hopfield networks.**" The Eleventh International Conference on Learning Representations. 2022.
[[Paper](https://arxiv.org/abs/2305.05179)]

* [Neural Computation] Ota, Toshihiro, and Ryo Karakida. "**Attention in a family of Boltzmann machines emerging from modern Hopfield networks.**" Neural Computation 35.8 (2023): 1463-1480.
[[Paper](https://arxiv.org/pdf/2212.04692.pdf)] [[Code](https://github.com/Toshihiro-Ota/AttnBM)]

* [ICLR 2022] Zhang, Jinsong, et al. "**Out-of-Distribution Detection based on In-Distribution Data Patterns Memorization with Modern Hopfield Energy.**" The Eleventh International Conference on Learning Representations. 2022. [[Paper](https://openreview.net/forum?id=KkazG4lgKL)] [[Code](https://github.com/zjs975584714/SHE)] 


## Year 2022 

* Seidl, Philipp, et al. "**Improving few-and zero-shot reaction template prediction using modern hopfield networks**." Journal of chemical information and modeling 62.9 (2022): 2111-2120.
  [[Paper](https://pubs.acs.org/doi/epdf/10.1021/acs.jcim.1c01065)]
  [[Code](https://github.com/ml-jku/mhn-react)]
  [[Video](https://youtu.be/xv3blKfpPww?si=NsnaoYOIgdKW_bYe)]

* [NeurIPS 2022] Iatropoulos, Georgios, Johanni Brea, and Wulfram Gerstner. "**Kernel Memory Networks: A Unifying Framework for Memory Modeling.**" Advances in Neural Information Processing Systems 35 (2022): 35326-35338. [[Paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/e55d081280e79e714debf2902e18eb69-Paper-Conference.pdf)] 

* Millidge B, Salvatori T, Song Y, et al. **Universal hopfield networks: A general framework for single-shot associative memory models**[C]//International Conference on Machine Learning. PMLR, 2022: 15561-15583.
[[Paper](https://proceedings.mlr.press/v162/millidge22a.html)]
[[Code](https://github.com/BerenMillidge/Theory_Associative_Memory)] 

* [IEEE TIP-2023] Xu, Yonghao, et al. "**Txt2Img-MHN: Remote sensing image generation from text using modern Hopfield networks**." arXiv preprint arXiv:2208.04441 (2022). 
[[Paper](https://arxiv.org/abs/2208.04441)] [[Code](https://github.com/YonghaoXu/Txt2Img-MHN)]

* Seidl, Philipp, et al. "**Improving few-and zero-shot reaction template prediction using modern hopfield networks.**" Journal of chemical information and modeling 62.9 (2022): 2111-2120.
[[Paper](https://pubs.acs.org/doi/full/10.1021/acs.jcim.1c01065)] [[Code](http://github.com/ml-jku/mhn-react)]

* [NIPS-2022] Fürst, Andreas, et al. "**Cloob: Modern hopfield networks with infoloob outperform clip.**" Advances in neural information processing systems 35 (2022): 20450-20468.
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/8078e76f913e31b8467e85b4c0f0d22b-Paper-Conference.pdf)] [[Code](https://github.com/ml-jku/cloob)]

* Schäfl, Bernhard, et al. "**Hopular: Modern hopfield networks for tabular data.**" arXiv preprint arXiv:2206.00664 (2022).
[[Paper](https://arxiv.org/abs/2206.00664)]
[[Code](https://github.com/ml-jku/hopular)]
[[Blog](https://ml-jku.github.io/hopular/)]



## Year 2021 and Before 
* [ICLR 2021] Ramsauer, Hubert, et al. "**Hopfield Networks is All You Need**." International Conference on Learning Representations. 2021
[[Paper](https://openreview.net/forum?id=tL89RnzIiCd)] [[Code](https://github.com/ml-jku/hopfield-layers)] [[Project Page](https://ml-jku.github.io/hopfield-layers/)]

* [NIPS-2020] Widrich, Michael, et al. "**Modern hopfield networks and attention for immune repertoire classification.**" Advances in Neural Information Processing Systems 33 (2020): 18832-18845.
[[Paper](https://proceedings.neurips.cc/paper_files/paper/2020/file/da4902cb0bc38210839714ebdcf0efc3-Paper.pdf)] [[Code](https://github.com/ml-jku/DeepRC)]

* [Workshop NeurIPS 2021] Widrich, Michael, et al. "**Modern hopfield networks for return decomposition for delayed rewards.**" Deep RL Workshop NeurIPS 2021. 2021.

* [Frontiers in big Data (2022)] Liang, Yuchen, Dmitry Krotov, and Mohammed J. Zaki. "**Modern Hopfield Networks for graph embedding**." Frontiers in big Data 5 (2022): 1044709. [[Paper](https://www.frontiersin.org/articles/10.3389/fdata.2022.1044709/full)]

* Seidl, Philipp, et al. "**Modern hopfield networks for few-and zero-shot reaction template prediction.**" arXiv preprint arXiv:2104.03279 (2021).

* [Workshop NeurIPS 2021] **Modern Hopfield Networks for Sample-Efficient Return Decomposition from Demonstrations**, [[Paper](https://offline-rl-neurips.github.io/2021/pdf/15.pdf)] 








